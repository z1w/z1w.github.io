---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a research scientist at Meta. Previously, I was at the University of Wisconsinâ€“Madison, where I was advised by [Somesh Jha](https://pages.cs.wisc.edu/~jha/), prior to that, by by [Ben Liblit](https://pages.cs.wisc.edu/~liblit/). I was affliated with the fantasitic [madPL](https://madpl.cs.wisc.edu/) group and have had the privilege of being mentored by [Thomas Reps](https://pages.cs.wisc.edu/~reps/), [Aws Albarghouthi](https://pages.cs.wisc.edu/~aws/) and [Yudong Chen](https://pages.cs.wisc.edu/~yudongchen/). 

My research is situated at the intersection of programming languages and deep learning, guided by a broad interest in computational and linguistic problems and a tendency to interpret challenges through these lenses. I am particularly dedicated to formalizing computational phenomena in deep learningâ€”a process known as abstracting in computer science and modeling in physics. My research philosophy draws significant inspiration from Immanuel Kant and the classical GÃ¶ttingen school of mathematicians. Currently, I employ meta-programming techniques to investigate and harness emergent linguistic phenomena and novel computational paradigms within language models. Previously, my work has focused on analyzing the variational properties of neural networks.

I studied mathematics and philosophy at the University of Illinois Urbana-Champaign as an undergraduate. I also completed a master degree in computer science at the Courant Institute, New York University, before moving to Madison. At New York University, my research advisor was [Richard Cole](https://cs.nyu.edu/~cole/).

The best way to reach me is my email: "MyInitials (two letters) at cs.wisc.edu" (for example, <pl@cs.wisc.edu>).

Publications and manuscripts
======
**Zi Wang**, **Shiwei Weng**, Mohannad Alhanahnah, Somesh Jha and Tom Reps. [PEA: Enhancing LLM Performance on Computational-Reasoning Tasks](https://arxiv.org/abs/2502.10938). Under Review

**Zi Wang**, **Divyam Anshumaan**, Ashish Hooda, Yudong Chen and Somesh Jha. [Functional Homotopy: Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks](https://openreview.net/forum?id=uhaLuZcCjH). ICLR 2025

**Zi Wang**, **Bin Hu**, Aaron Havens, Alexandre Araujo, Yang Zheng, Yudong Chen and Somesh Jha. [On the Scalability and Memory Efficiency of Semidefinite Programs for Lipschitz Constant Estimation of Neural Networks](https://openreview.net/forum?id=dwzLn78jq7). ICLR 2024

**Zi Wang**, Gautam Prakriya and Somesh Jha. [A Quantitative Geometric Approach to Neural Network Smoothness](https://openreview.net/forum?id=ZQcpYaE1z1r). NeurIPS 2022

**Zi Wang**, Aws Albarghouthi, Gautam Prakriya and Somesh Jha. [Interval Universal Approximation for Neural Networks](https://dl.acm.org/doi/10.1145/3498675). POPL 2022

Jordan Henkel, Goutham Ramakrishnan, **Zi Wang**, Aws Albarghouthi, Somesh Jha and Thomas Reps. [Semantic Robustness of Models of Source Code](https://arxiv.org/abs/2002.03043). SANER 2022

Thomas K. Panum, **Zi Wang**, Pengyu Kan, Earlence Fernandes and Somesh Jha. [Exploring Adversarial Robustness of Deep Metric Learning](https://arxiv.org/abs/2102.07265). arXiv preprint arXiv:2102.07265

**Zi Wang**, Ben Liblit and Thomas Reps. [TOFU: Target-Oriented FUzzer](https://arxiv.org/abs/2004.14375). arXiv preprint arXiv:2004.14375

**Zi Wang**, Jihye Choi, Ke Wang and Somesh Jha. [Rethinking Diversity in Deep Neural Network Testing](https://arxiv.org/abs/2305.15698). arXiv:2305.15698

**Zi Wang**. [A New Strongly Polynomial Algorithm for Computing Fisher Market Equilibria with Spending Constraint Utilities](https://cs.nyu.edu/media/publications/wang_zi.pdf). Master Thesis

Miscellaneous
=======
My recent favorite album is [RENAISSANCE](https://www.youtube.com/playlist?list=PLk7ySTbOWfFBHahXvFqY2K2wCOvcfYLpG). Great ideas will come back again and again ðŸ«¡.

My MOST favorite movie is [Life of Pi](https://en.wikipedia.org/wiki/Life_of_Pi_(film)). Life is full of metaphors, and the archetypes underneath the metaphors are the innate abstractions of the world.